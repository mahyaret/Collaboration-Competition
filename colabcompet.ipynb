{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration Competition\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you're in the right virtual environment and the right python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 3.6.8 :: Anaconda, Inc.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Windows'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python --version\n",
    "import platform\n",
    "platform.system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below.  Please run the next code cell without making any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from collections import deque\n",
    "import timeit\n",
    "from datetime import timedelta\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    env = UnityEnvironment(file_name=\"data/Tennis_Windows_x86_64/Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actor-Critic implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def build_hidden_layer(input_dim, hidden_layers):\n",
    "    \"\"\"Build hidden layer.\n",
    "    Params\n",
    "    ======\n",
    "        input_dim (int): Dimension of hidden layer input\n",
    "        hidden_layers (list(int)): Dimension of hidden layers\n",
    "    \"\"\"\n",
    "    hidden = nn.ModuleList([nn.Linear(input_dim, hidden_layers[0])])\n",
    "    if len(hidden_layers)>1:\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        hidden.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "    return hidden\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self,state_size,action_size,shared_layers,\n",
    "                 critic_hidden_layers=[],actor_hidden_layers=[],\n",
    "                 seed=0, init_type=None):\n",
    "        \"\"\"Initialize parameters and build policy.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            shared_layers (list(int)): Dimension of the shared hidden layers\n",
    "            critic_hidden_layers (list(int)): Dimension of the critic's hidden layers\n",
    "            actor_hidden_layers (list(int)): Dimension of the actor's hidden layers\n",
    "            seed (int): Random seed\n",
    "            init_type (str): Initialization type\n",
    "        \"\"\"\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.init_type = init_type\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.sigma = nn.Parameter(torch.zeros(action_size))\n",
    "\n",
    "        # Add shared hidden layer\n",
    "        self.shared_layers = build_hidden_layer(input_dim=state_size,\n",
    "                                                hidden_layers=shared_layers)\n",
    "\n",
    "        # Add critic layers\n",
    "        if critic_hidden_layers:\n",
    "            # Add hidden layers for critic net if critic_hidden_layers is not empty\n",
    "            self.critic_hidden = build_hidden_layer(input_dim=shared_layers[-1],\n",
    "                                                    hidden_layers=critic_hidden_layers)\n",
    "            self.critic = nn.Linear(critic_hidden_layers[-1], 1)\n",
    "        else:\n",
    "            self.critic_hidden = None\n",
    "            self.critic = nn.Linear(shared_layers[-1], 1)\n",
    "\n",
    "        # Add actor layers\n",
    "        if actor_hidden_layers:\n",
    "            # Add hidden layers for actor net if actor_hidden_layers is not empty\n",
    "            self.actor_hidden = build_hidden_layer(input_dim=shared_layers[-1],\n",
    "                                                   hidden_layers=actor_hidden_layers)\n",
    "            self.actor = nn.Linear(actor_hidden_layers[-1], action_size)\n",
    "        else:\n",
    "            self.actor_hidden = None\n",
    "            self.actor = nn.Linear(shared_layers[-1], action_size)\n",
    "\n",
    "        # Apply Tanh() to bound the actions\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        # Initialize hidden and actor-critic layers\n",
    "        if self.init_type is not None:\n",
    "            self.shared_layers.apply(self._initialize)\n",
    "            self.critic.apply(self._initialize)\n",
    "            self.actor.apply(self._initialize)\n",
    "            if self.critic_hidden is not None:\n",
    "                self.critic_hidden.apply(self._initialize)\n",
    "            if self.actor_hidden is not None:\n",
    "                self.actor_hidden.apply(self._initialize)\n",
    "\n",
    "    def _initialize(self, n):\n",
    "        \"\"\"Initialize network weights.\n",
    "        \"\"\"\n",
    "        if isinstance(n, nn.Linear):\n",
    "            if self.init_type=='xavier-uniform':\n",
    "                nn.init.xavier_uniform_(n.weight.data)\n",
    "            elif self.init_type=='xavier-normal':\n",
    "                nn.init.xavier_normal_(n.weight.data)\n",
    "            elif self.init_type=='kaiming-uniform':\n",
    "                nn.init.kaiming_uniform_(n.weight.data)\n",
    "            elif self.init_type=='kaiming-normal':\n",
    "                nn.init.kaiming_normal_(n.weight.data)\n",
    "            elif self.init_type=='orthogonal':\n",
    "                nn.init.orthogonal_(n.weight.data)\n",
    "            elif self.init_type=='uniform':\n",
    "                nn.init.uniform_(n.weight.data)\n",
    "            elif self.init_type=='normal':\n",
    "                nn.init.normal_(n.weight.data)\n",
    "            else:\n",
    "                raise KeyError('initialization type is not found in the set of existing types')\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> (action, value).\"\"\"\n",
    "        def apply_multi_layer(layers,x,f=F.leaky_relu):\n",
    "            for layer in layers:\n",
    "                x = f(layer(x))\n",
    "            return x\n",
    "\n",
    "        state = apply_multi_layer(self.shared_layers,state)\n",
    "\n",
    "        v_hid = state\n",
    "        if self.critic_hidden is not None:\n",
    "            v_hid = apply_multi_layer(self.critic_hidden,v_hid)\n",
    "\n",
    "        a_hid = state\n",
    "        if self.actor_hidden is not None:\n",
    "            a_hid = apply_multi_layer(self.actor_hidden,a_hid)\n",
    "\n",
    "        a = self.tanh(self.actor(a_hid))\n",
    "        value = self.critic(v_hid).squeeze(-1)\n",
    "        return a, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the state and action spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")#\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectories(envs, policy, tmax=200, nrand=5, train_mode=False):\n",
    "\n",
    "    def to_tensor(x, dtype=np.float32):\n",
    "        return torch.from_numpy(np.array(x).astype(dtype)).to(device)\n",
    "\n",
    "    #initialize returning lists and start the game!\n",
    "    state_list=[]\n",
    "    reward_list=[]\n",
    "    prob_list=[]\n",
    "    action_list=[]\n",
    "    value_list=[]\n",
    "    done_list=[]\n",
    "\n",
    "    env_info = envs.reset(train_mode=train_mode)[brain_name]\n",
    "\n",
    "    # perform nrand random steps\n",
    "    for _ in range(nrand):\n",
    "        action = np.random.randn(num_agents, action_size)\n",
    "        action = np.clip(action, -1.0, 1.0)\n",
    "        env_info = envs.step(action)[brain_name]\n",
    "\n",
    "    for t in range(tmax):\n",
    "        states = to_tensor(env_info.vector_observations)\n",
    "        action_est, values = policy(states)\n",
    "        sigma = nn.Parameter(torch.zeros(action_size))\n",
    "        dist = torch.distributions.Normal(action_est, F.softplus(sigma).to(device))\n",
    "        actions = dist.sample()\n",
    "        log_probs = dist.log_prob(actions)\n",
    "        log_probs = torch.sum(log_probs, dim=-1).detach()\n",
    "        values = values.detach()\n",
    "        actions = actions.detach()\n",
    "\n",
    "        env_actions = actions.cpu().numpy()\n",
    "        env_info = envs.step(env_actions)[brain_name]\n",
    "        rewards = to_tensor(env_info.rewards)\n",
    "        dones = to_tensor(env_info.local_done, dtype=np.uint8)\n",
    "\n",
    "        state_list.append(states.unsqueeze(0))\n",
    "        prob_list.append(log_probs.unsqueeze(0))\n",
    "        action_list.append(actions.unsqueeze(0))\n",
    "        reward_list.append(rewards.unsqueeze(0))\n",
    "        value_list.append(values.unsqueeze(0))\n",
    "        done_list.append(dones.unsqueeze(0))\n",
    "        #if np.any(dones.cpu().numpy()):\n",
    "        if np.any(dones.numpy()):\n",
    "            env_info = envs.reset(train_mode=train_mode)[brain_name]\n",
    "\n",
    "    state_list = torch.cat(state_list, dim=0)\n",
    "    prob_list = torch.cat(prob_list, dim=0)\n",
    "    action_list = torch.cat(action_list, dim=0)\n",
    "    reward_list = torch.cat(reward_list, dim=0)\n",
    "    value_list = torch.cat(value_list, dim=0)\n",
    "    done_list = torch.cat(done_list, dim=0)\n",
    "    return prob_list, state_list, action_list, reward_list, value_list, done_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_returns(rewards, values, dones):\n",
    "    n_step = len(rewards)\n",
    "    n_agent = len(rewards[0])\n",
    "\n",
    "    # Create empty buffer\n",
    "    GAE = torch.zeros(n_step,n_agent).float().to(device)\n",
    "    returns = torch.zeros(n_step,n_agent).float().to(device)\n",
    "\n",
    "    # Set start values\n",
    "    GAE_current = torch.zeros(n_agent).float().to(device)\n",
    "\n",
    "    TAU = 0.95\n",
    "    discount = 0.99\n",
    "    values_next = values[-1].detach()\n",
    "    returns_current = values[-1].detach()\n",
    "    for irow in reversed(range(n_step)):\n",
    "        values_current = values[irow]\n",
    "        rewards_current = rewards[irow]\n",
    "        gamma = discount * (1. - dones[irow].float())\n",
    "\n",
    "        # Calculate TD Error\n",
    "        td_error = rewards_current + gamma * values_next - values_current\n",
    "        # Update GAE, returns\n",
    "        GAE_current = td_error + gamma * TAU * GAE_current\n",
    "        returns_current = rewards_current + gamma * returns_current\n",
    "        # Set GAE, returns to buffer\n",
    "        GAE[irow] = GAE_current\n",
    "        returns[irow] = returns_current\n",
    "\n",
    "        values_next = values_current\n",
    "\n",
    "    return GAE, returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_policy(envs, policy, tmax=1000):\n",
    "    reward_list=[]\n",
    "    env_info = envs.reset(train_mode=False)[brain_name]\n",
    "    for t in range(tmax):\n",
    "        states = torch.from_numpy(env_info.vector_observations).float().to(device)\n",
    "        action_est, values = policy(states)\n",
    "        sigma = nn.Parameter(torch.zeros(action_size))\n",
    "        dist = torch.distributions.Normal(action_est, F.softplus(sigma).to(device))\n",
    "        actions = dist.sample()\n",
    "        env_actions = actions.cpu().numpy()\n",
    "        env_info = envs.step(env_actions)[brain_name]\n",
    "        reward = env_info.rewards\n",
    "        dones = env_info.local_done\n",
    "        reward_list.append(np.mean(reward))\n",
    "\n",
    "        # stop if any of the trajectories is done to have retangular lists\n",
    "        if np.any(dones):\n",
    "            break\n",
    "    return reward_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "An actor-critic structure with continuous action space is used for this project. The policy consists of 3 parts, a shared hidden layers, actor, and critic.\n",
    "The actor layer outputs the mean value of a normal distribution, from which the agent's action is sampled. The critic layer yields the value function.\n",
    "\n",
    "- Shared layer:\n",
    "```\n",
    "Input State(33) -> Dense(128) -> LeakyReLU -> Dense(128) -> LeakyReLU*\n",
    "```\n",
    "- Actor and Critic layers:\n",
    "```\n",
    "LeakyRelu* -> Dense(64) -> LeakyRelu -> Dense(4)-> tanh -> Actor's output\n",
    "LeakyReLU* -> Dense(64) -> LeakyRelu -> Dense(1) -> Critic's output\n",
    "```\n",
    "\n",
    "### Model update using PPO/GAE\n",
    "The hyperparameters used during training are:\n",
    "\n",
    "Parameter | Value | Description\n",
    "------------ | ------------- | -------------\n",
    "Number of Agents | 2 | Number of agents\n",
    "Episodes | 2000 | Maximum number of training episodes\n",
    "tmax | 1000 | Maximum number of steps per episode\n",
    "Epochs | 10 | Number of training epoch per batch sampling\n",
    "Batch size | 128*20 | Size of batch taken from the accumulated  trajectories\n",
    "Discount (gamma) | 0.995 | Discount rate \n",
    "Epsilon | 0.05 | Ratio used to clip r = new_probs/old_probs during training\n",
    "Gradient clip | 10.0 | Maximum gradient norm \n",
    "Beta | 0.01 | Entropy coefficient \n",
    "Tau | 0.95 | tau coefficient in GAE\n",
    "Learning rate | 2e-4 | Learning rate \n",
    "Optimizer | Adam | Optimization method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run your own policy!\n",
    "policy=ActorCritic(state_size=state_size,\n",
    "              action_size=action_size,\n",
    "              shared_layers=[128, 64],\n",
    "              critic_hidden_layers=[],\n",
    "              actor_hidden_layers=[],\n",
    "              init_type='xavier-uniform',\n",
    "              seed=0).to(device)\n",
    "\n",
    "# we use the adam optimizer with learning rate 2e-4\n",
    "# optim.SGD is also possible\n",
    "optimizer = optim.Adam(policy.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 10, average score: -0.03\n",
      "Episode: 20, average score: -0.05\n",
      "Episode: 30, average score: -0.01\n",
      "Episode: 40, average score: 0.02\n",
      "Episode: 50, average score: 0.04\n",
      "Episode: 60, average score: 0.05\n",
      "Episode: 70, average score: 0.08\n",
      "Episode: 80, average score: 0.11\n",
      "Episode: 90, average score: 0.14\n",
      "Episode: 100, average score: 0.18\n",
      "Episode: 110, average score: 0.24\n",
      "Episode: 120, average score: 0.30\n",
      "Episode: 130, average score: 0.35\n",
      "Episode: 140, average score: 0.40\n",
      "Episode: 150, average score: 0.47\n",
      "Episode: 160, average score: 0.53\n",
      "Episode: 170, average score: 0.58\n",
      "Episode: 180, average score: 0.62\n",
      "Episode: 190, average score: 0.66\n",
      "Episode: 200, average score: 0.70\n",
      "Episode: 210, average score: 0.75\n",
      "Episode: 220, average score: 0.81\n",
      "Episode: 230, average score: 0.87\n",
      "Episode: 240, average score: 0.92\n",
      "Episode: 250, average score: 0.98\n",
      "Environment solved in 253 episodes!\tAverage Score: 1.00\n",
      "Average Score: 1.00\n",
      "Elapsed time: 0:12:34.734125\n",
      "Saving checkpoint!\n"
     ]
    }
   ],
   "source": [
    "scores_window = deque(maxlen=100)  # last 100 scores\n",
    "\n",
    "discount = 0.995\n",
    "epsilon = 0.05\n",
    "beta = .01\n",
    "opt_epoch = 10\n",
    "episode = 2000\n",
    "batch_size = 128\n",
    "tmax = 1000 #env episode steps\n",
    "\n",
    "save_scores = []\n",
    "\n",
    "print_per_n = min(10,episode/10)\n",
    "counter = 0\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "for e in range(episode):\n",
    "    policy.eval()\n",
    "    old_probs_lst, states_lst, actions_lst, rewards_lst, values_lst, dones_list = collect_trajectories(envs=env,\n",
    "                                                                                                       policy=policy,\n",
    "                                                                                                       tmax=tmax,\n",
    "                                                                                                       nrand = 0,\n",
    "                                                                                                       train_mode=True)\n",
    "\n",
    "    avg_score = rewards_lst.sum(dim=0).mean().item()\n",
    "    scores_window.append(avg_score)\n",
    "    save_scores.append(avg_score)\n",
    "    \n",
    "    gea, target_value = calc_returns(rewards = rewards_lst,\n",
    "                                     values = values_lst,\n",
    "                                     dones=dones_list)\n",
    "    gea = (gea - gea.mean()) / (gea.std() + 1e-8)\n",
    "\n",
    "    policy.train()\n",
    "\n",
    "    # cat all agents\n",
    "    def concat_all(v):\n",
    "        if len(v.shape) == 3:\n",
    "            return v.reshape([-1, v.shape[-1]])\n",
    "        return v.reshape([-1])\n",
    "\n",
    "    old_probs_lst = concat_all(old_probs_lst)\n",
    "    states_lst = concat_all(states_lst)\n",
    "    actions_lst = concat_all(actions_lst)\n",
    "    rewards_lst = concat_all(rewards_lst)\n",
    "    values_lst = concat_all(values_lst)\n",
    "    gea = concat_all(gea)\n",
    "    target_value = concat_all(target_value)\n",
    "\n",
    "    # gradient ascent step\n",
    "    n_sample = len(old_probs_lst)//batch_size\n",
    "    idx = np.arange(len(old_probs_lst))\n",
    "    np.random.shuffle(idx)\n",
    "    for epoch in range(opt_epoch):\n",
    "        for b in range(n_sample):\n",
    "            ind = idx[b*batch_size:(b+1)*batch_size]\n",
    "            g = gea[ind]\n",
    "            tv = target_value[ind]\n",
    "            actions = actions_lst[ind]\n",
    "            old_probs = old_probs_lst[ind]\n",
    "\n",
    "            action_est, values = policy(states_lst[ind])\n",
    "            sigma = nn.Parameter(torch.zeros(action_size))\n",
    "            dist = torch.distributions.Normal(action_est, F.softplus(sigma).to(device))\n",
    "            log_probs = dist.log_prob(actions)\n",
    "            log_probs = torch.sum(log_probs, dim=-1)\n",
    "            entropy = torch.sum(dist.entropy(), dim=-1)\n",
    "\n",
    "            ratio = torch.exp(log_probs - old_probs)\n",
    "            ratio_clipped = torch.clamp(ratio, 1 - epsilon, 1 + epsilon)\n",
    "            L_CLIP = torch.mean(torch.min(ratio*g, ratio_clipped*g))\n",
    "            # entropy bonus\n",
    "            S = entropy.mean()\n",
    "            # squared-error value function loss\n",
    "            L_VF = 0.5 * (tv - values).pow(2).mean()\n",
    "            # clipped surrogate\n",
    "            L = -(L_CLIP - L_VF + beta*S)\n",
    "            optimizer.zero_grad()\n",
    "            # This may need retain_graph=True on the backward pass\n",
    "            # as pytorch automatically frees the computational graph after\n",
    "            # the backward pass to save memory\n",
    "            # Without this, the chain of derivative may get lost\n",
    "            L.backward(retain_graph=True)\n",
    "            torch.nn.utils.clip_grad_norm_(policy.parameters(), 10.0)\n",
    "            optimizer.step()\n",
    "            del(L)\n",
    "\n",
    "    # the clipping parameter reduces as time goes on\n",
    "    epsilon*=.999\n",
    "    \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    beta*=.998\n",
    "    \n",
    "    # display some progress every n iterations\n",
    "    if (e+1)%print_per_n ==0 :\n",
    "        print(\"Episode: {0:d}, average score: {1:.2f}\".format(e+1,np.mean(scores_window)), end=\"\\n\")\n",
    "    else:\n",
    "        print(\"Episode: {0:d}, score: {1:.2f}\".format(e+1, avg_score), end=\"\\r\")\n",
    "    if np.mean(scores_window)<5.0:\n",
    "        counter = 0# stop if any of the trajectories is done to have retangular lists\n",
    "    if e>=25 and np.mean(scores_window)>1.0:\n",
    "        print('Environment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(e+1, np.mean(scores_window)))\n",
    "        break\n",
    "\n",
    "\n",
    "print('Average Score: {:.2f}'.format(np.mean(scores_window)))\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Elapsed time: {}\".format(timedelta(seconds=elapsed)))\n",
    "print(\"Saving checkpoint!\")\n",
    "# save your policy!\n",
    "torch.save(policy.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(len(save_scores)), save_scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, score: -0.004999999888241291\n",
      "Episode: 2, score: 0.04500000085681677\n",
      "Episode: 3, score: 0.04500000085681677\n",
      "Episode: 4, score: 0.032500000670552254\n",
      "Episode: 5, score: 0.025000000558793544\n",
      "Episode: 6, score: 0.02000000048428774\n",
      "Episode: 7, score: 0.016428571859640733\n",
      "Episode: 8, score: 0.013750000391155481\n",
      "Episode: 9, score: 0.011666667026778063\n",
      "Episode: 10, score: 0.010000000335276127\n"
     ]
    }
   ],
   "source": [
    "episode = 10\n",
    "scores_window = deque(maxlen=100)  # last 100 scores\n",
    "\n",
    "# load the model\n",
    "policy.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "# evaluate the model\n",
    "for e in range(episode):\n",
    "    rewards = eval_policy(envs=env, policy=policy, tmax=1000)\n",
    "    total_rewards = np.sum(rewards,0)\n",
    "    scores_window.append(total_rewards.mean())\n",
    "    print(\"Episode: {0:d}, score: {1}\".format(e+1, np.mean(scores_window)), end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "1. Hyperparameter optimization and analysis.\n",
    "2. Studying the effect of clipping."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
